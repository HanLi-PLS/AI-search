# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# OpenAI API Configuration
# Option 1: AWS Secrets Manager (RECOMMENDED for EC2/production)
# When running on EC2, set USE_AWS_SECRETS=true and the backend will automatically
# fetch the OpenAI API key from AWS Secrets Manager using the EC2 IAM role
USE_AWS_SECRETS=true
AWS_SECRET_NAME_OPENAI=openai-api-key

# Option 2: Direct API Key (for local development only - NOT RECOMMENDED for production)
# If USE_AWS_SECRETS=false, you must set OPENAI_API_KEY below
# IMPORTANT: Never commit this file with a real API key!
# OPENAI_API_KEY=your-openai-api-key-here

# Vision Model for PDF Image Processing
# Options: gpt-5.2 (faster, cheaper) or gpt-4o (more capable)
VISION_MODEL=gpt-5.2

# Answer Generation Model (for answering user questions)
# Options: gpt-5.2 (recommended), gpt-4o, o3, gpt-4-turbo
ANSWER_MODEL=gpt-5.2
# Temperature for answer generation (0 = deterministic, 1 = creative)
ANSWER_TEMPERATURE=0

# AWS Configuration
# IMPORTANT: When running on EC2 with IAM role, do NOT set AWS_ACCESS_KEY_ID or AWS_SECRET_ACCESS_KEY
# The backend will automatically use the EC2 instance's IAM role credentials
#
# For EC2: Leave these commented out - IAM role will be used automatically
# For Local Development: Uncomment and set these if you don't have AWS CLI configured
# AWS_ACCESS_KEY_ID=your-aws-access-key
# AWS_SECRET_ACCESS_KEY=your-aws-secret-key

# AWS Region (must match where your secrets are stored)
AWS_REGION=us-west-2

# S3 Storage Configuration
# Set USE_S3_STORAGE=true to store uploaded files in S3 instead of local disk
USE_S3_STORAGE=false
AWS_S3_BUCKET=plfs-han-ai-search
S3_UPLOAD_PREFIX=uploads/

# AWS Athena Configuration (for IPO data)
# Database name in Athena (default: capiq or production)
ATHENA_DATABASE=production
# S3 location for Athena query results (must end with /)
ATHENA_OUTPUT_LOCATION=s3://aws-athena-query-results-185381186363-us-west-2/

# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=documents

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Alternative: Alibaba-NLP/gte-multilingual-base (better multilingual, needs GPU or faster CPU), Qwen/Qwen3-Embedding-0.6B (slow on CPU)

# Document Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_FILE_SIZE_MB=100
# Max concurrent o4-mini vision API calls during PDF processing (default: 10)
# Higher = faster but may hit rate limits. Lower = slower but more stable.
MAX_CONCURRENT_VISION_CALLS=10

# Upload Configuration
UPLOAD_DIR=./uploads
DATA_DIR=./data

# Authentication (future use)
SECRET_KEY=your-secret-key-for-jwt
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
