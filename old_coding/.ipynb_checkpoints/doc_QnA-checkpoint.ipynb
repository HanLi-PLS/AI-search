{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf95bfd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture --no-stderr\n",
    "%run docIndex.ipynb\n",
    "#!pip install --upgrade openai\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate\n",
    "!pip install rank_bm25\n",
    "!pip install markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# import sagemaker\n",
    "# from sagemaker import get_execution_role\n",
    "\n",
    "from langchain.llms import BaseLLM\n",
    "from ipywidgets import Dropdown\n",
    "# from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "import markdown\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import os, gc, torch\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import chromadb \n",
    "from chromadb import Settings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import requests\n",
    "\n",
    "# from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "#from langchain_community.vectorstores import Chroma   # instead of langchain_chroma\n",
    "\n",
    "from transformers import set_seed\n",
    "\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from transformers.utils import is_bitsandbytes_available\n",
    "\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.retrievers.ensemble import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf64f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run this for the first time to process pdfs, no need to run again after that except there are new files added\n",
    "s3_bucket = 'plfs-han-llm-experiment'\n",
    "s3_source_folder = 'factsheet-generation/PPInnova/internal/jarvis_docs/'\n",
    "s3_output_folder = 'factsheet-generation/PPInnova/internal/jarvis_docs/'\n",
    "process_pdfs_in_s3_folder(s3_bucket, s3_source_folder, s3_bucket, s3_output_folder, model=\"o4-mini\")  #gpt-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e258cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open and save the PDF to potentially fix issues\n",
    "# doc1 = fitz.open(\"Euhearing_sharepoint_selected_20250921--01 From company--项目相关资料包-Euhearing_20250817091531.pdf\")\n",
    "# doc1.save(\"Euhearing_sharepoint_selected_20250921--01 From company--项目相关资料包-Euhearing_20250817091531_repaired.pdf\", garbage=4, deflate=True, clean=True)\n",
    "# doc1.close()\n",
    "\n",
    "# # # Now try with the repaired version\n",
    "# doc1 = fitz.open(\"Euhearing_sharepoint_selected_20250921--01 From company--项目相关资料包-Euhearing_20250817091531_repaired.pdf\")\n",
    "# text1 = doc1[1].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d59906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#if there are new files added, run this to process unprocessed pdfs\n",
    "s3_bucket = 'plfs-han-llm-experiment'\n",
    "s3_source_folder = 'factsheet-generation/Euhearing/internal/jarvis_docs/'\n",
    "s3_output_folder = 'factsheet-generation/Euhearing/internal/jarvis_docs/'\n",
    "process_unprocessed_pdfs_in_s3_folder(s3_bucket, s3_source_folder, s3_bucket, s3_output_folder, model=\"o4-mini\")  #gpt-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246458c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files_flattened_and_renamed_within_s3(bucket_name, source_prefix, destination_prefix):\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=source_prefix)\n",
    "    if 'Contents' not in response:\n",
    "        print(f\"No files found in {source_prefix}\")\n",
    "        return\n",
    "\n",
    "    for obj in response['Contents']:\n",
    "        source_key = obj['Key']\n",
    "        if source_key.endswith('/'):\n",
    "            continue  # Skip directories\n",
    "\n",
    "        # Extract the relative path from source_prefix\n",
    "        relative_path = os.path.relpath(source_key, source_prefix)\n",
    "        \n",
    "        # Extract the top folder name\n",
    "        top_folder_name = relative_path.split('/')[0]\n",
    "        \n",
    "        # Extract the original file name\n",
    "        original_file_name = os.path.basename(source_key)\n",
    "        \n",
    "        # Create the new file name with the folder name included\n",
    "        new_file_name = f\"{top_folder_name}_{original_file_name}\"\n",
    "        \n",
    "        # Construct the destination key\n",
    "        destination_key = f\"{destination_prefix.rstrip('/')}/{new_file_name}\"\n",
    "        \n",
    "        # Copy the object to the new location\n",
    "        copy_source = {'Bucket': bucket_name, 'Key': source_key}\n",
    "        s3.copy_object(CopySource=copy_source, Bucket=bucket_name, Key=destination_key)\n",
    "        \n",
    "        print(f\"Copied {source_key} to {destination_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RecursiveCharacterTextSplitter\n",
    "def process_documents_from_s3(s3_bucket: str, s3_folder: str, ignored_files: List[str] = []) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load documents from S3 and split in chunks\n",
    "    \"\"\"\n",
    "    print(f\"Loading documents from s3://{s3_bucket}/{s3_folder}\")\n",
    "    documents = load_documents_from_s3(s3_bucket, s3_folder, ignored_files)\n",
    "    if not documents:\n",
    "        print(\"No new documents to load\")\n",
    "        exit(0)\n",
    "    print(f\"Loaded {len(documents)} new documents from s3://{s3_bucket}/{s3_folder}\")\n",
    "    \n",
    "    #the chunk_size parameter in RecursiveCharacterTextSplitter refers to the number of characters\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Add filename to each chunk after splitting\n",
    "    for chunk in texts:\n",
    "        filename = chunk.metadata.get('source', 'unknown_file')\n",
    "        chunk.page_content = f\"From file: {filename}\\n\\n{chunk.page_content}\"\n",
    "    \n",
    "    print(f\"Split into {len(texts)} chunks of text (max. {chunk_size} tokens each)\")\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ad97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_INT8 = True          # flip to True after `pip install bitsandbytes`\n",
    "embeddings_model_name = \"Qwen/Qwen3-Embedding-4B\"\n",
    "#RecursiveCharacterTextSplitter, size of chars\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 200\n",
    "\n",
    "\n",
    "class SentenceTransformerEmbeddings(Embeddings):\n",
    "    def __init__(self,\n",
    "                 model_name: str,\n",
    "                 device: str = \"cpu\",\n",
    "                 batch_size: int = 8,\n",
    "                 max_length: int = 8192,):\n",
    "        self.device     = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # minimise CUDA fragmentation\n",
    "        os.environ.setdefault(\n",
    "            \"PYTORCH_CUDA_ALLOC_CONF\",\n",
    "            \"expandable_segments:True,max_split_size_mb:128\"\n",
    "        )\n",
    "        gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "        # --------------------- build kwargs ------------------------------\n",
    "        load_kwargs = {\"trust_remote_code\": True}\n",
    "        if device == \"cuda\":\n",
    "            if USE_INT8 and is_bitsandbytes_available():\n",
    "                load_kwargs[\"model_kwargs\"] = {\n",
    "                    \"load_in_8bit\": True,\n",
    "                    \"device_map\": \"auto\",\n",
    "                }                \n",
    "            else:\n",
    "                load_kwargs[\"model_kwargs\"] = {\"torch_dtype\": torch.float16}\n",
    "\n",
    "        # --------------------- load model -------------------------------\n",
    "        self.model = SentenceTransformer(model_name, **load_kwargs)\n",
    "\n",
    "        # If we took the fp16 path, cast & move once\n",
    "        if device == \"cuda\" and not (USE_INT8 and is_bitsandbytes_available()):\n",
    "            self.model.half()          # weights → fp16\n",
    "            self.model.to(device)      # onto GPU\n",
    "\n",
    "    # --------------------- LangChain hooks ------------------------------\n",
    "    def embed_documents(self, documents: List[str]) -> List[List[float]]:\n",
    "        vecs = self.model.encode(\n",
    "            documents,\n",
    "            batch_size=self.batch_size,\n",
    "            convert_to_numpy=True,\n",
    "            show_progress_bar=False,\n",
    "            device=self.device,\n",
    "        )\n",
    "        return vecs.tolist()\n",
    "\n",
    "    def embed_query(self, query: str) -> List[float]:\n",
    "        return self.embed_documents([query])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4985e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "set_seed(42)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embeddings_model_name,\n",
    "    model_kwargs={'device': DEVICE},\n",
    "    encode_kwargs={'batch_size': 8, 'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# ChromaDB setup - this should work now\n",
    "current_dir = os.getcwd()\n",
    "persist_directory_jd = os.path.join(current_dir, \"chroma_db_jarvis_docs\")\n",
    "os.makedirs(persist_directory_jd, exist_ok=True)\n",
    "chroma_client_jd = chromadb.PersistentClient(path=persist_directory_jd)\n",
    "\n",
    "# Drop & recreate collection \n",
    "try:\n",
    "    chroma_client_jd.delete_collection(\"jarvis_docs\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "db_jd = Chroma(\n",
    "    collection_name=\"jarvis_docs\",\n",
    "    embedding_function=embeddings,  # Using external embeddings\n",
    "    client=chroma_client_jd,\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    ")\n",
    "\n",
    "\n",
    "s3_bucket = \"plfs-han-llm-experiment\"\n",
    "s3_folder = 'factsheet-generation/PPInnova/internal/jarvis_docs/'\n",
    "ignored_files = []\n",
    "texts = process_documents_from_s3(s3_bucket, s3_folder, ignored_files)\n",
    "\n",
    "CHROMA_BATCH_SIZE = 1000\n",
    "print(f\"Total documents to process: {len(texts)} (batch {CHROMA_BATCH_SIZE})\")\n",
    "\n",
    "for i in range(0, len(texts), CHROMA_BATCH_SIZE):\n",
    "    batch_texts = texts[i : i + CHROMA_BATCH_SIZE]\n",
    "    print(f\"Adding docs {i}-{i+len(batch_texts)-1}\")\n",
    "    db_jd.add_documents(batch_texts)\n",
    "    \n",
    "    if DEVICE == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"Vector database creation completed successfully!\")\n",
    "print(\"Final document count:\", chroma_client_jd.get_collection(\"jarvis_docs\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319fd18b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## load saved vectordb\n",
    "# Init the same embedding function you used to build the DB\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 8 if DEVICE == \"cuda\" else 64\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name=embeddings_model_name,\n",
    "    device=DEVICE,\n",
    "    batch_size=batch_size,\n",
    "    max_length=8192\n",
    ")\n",
    "\n",
    "\n",
    "persist_directory_jd = os.path.join(os.getcwd(), \"chroma_db_jarvis_docs\")\n",
    "chroma_client_jd   = chromadb.PersistentClient(path=persist_directory_jd)\n",
    "db_jd = Chroma(\n",
    "    client=chroma_client_jd,\n",
    "    collection_name=\"jarvis_docs\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "\n",
    "# persist_directory_jt = os.path.join(os.getcwd(), \"chroma_db_jarvis_tables\")\n",
    "# chroma_client_jt   = chromadb.PersistentClient(path=persist_directory_jt)\n",
    "# db_jt = Chroma(\n",
    "#     client=chroma_client_jt,\n",
    "#     collection_name=\"jarvis_tables\",\n",
    "#     embedding_function=embeddings\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88cd1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_contents_only(collection, batch_size=1000):\n",
    "    all_contents = []\n",
    "    offset = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f\"Processing batch starting at offset {offset}...\")\n",
    "        \n",
    "        # Get only documents, no metadata or embeddings\n",
    "        batch_data = collection.get(\n",
    "            limit=batch_size,\n",
    "            offset=offset,\n",
    "            include=[\"documents\"]  # Only text content\n",
    "        )\n",
    "        \n",
    "        if not batch_data['documents']:\n",
    "            break\n",
    "            \n",
    "        all_contents.extend(batch_data['documents'])\n",
    "        offset += batch_size\n",
    "        print(f\"Processed {len(all_contents)} documents so far...\")\n",
    "    \n",
    "    return all_contents\n",
    "\n",
    "# Use the batched approach\n",
    "collection = chroma_client_jd.get_collection(\"jarvis_docs\")\n",
    "all_page_contents = get_page_contents_only(collection, batch_size=1000)  \n",
    "\n",
    "with open('all_page_contents_docs.pkl', 'wb') as f:\n",
    "    pickle.dump(all_page_contents, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_page_contents_docs.pkl', 'rb') as f:\n",
    "    all_page_contents = pickle.load(f)\n",
    "\n",
    "all_docs = [Document(page_content=content) for content in all_page_contents]\n",
    "bm25_retriever = BM25Retriever.from_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8448f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(secret_name,region_name):\n",
    "\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    key = ast.literal_eval(secret)['key']\n",
    "    \n",
    "    return key\n",
    "\n",
    "openai_api_key=get_key(\"openai-api-key\", \"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fdde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_gpt(prompt):\n",
    "    \n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key = get_key(\"openai-api-key\",\"us-west-2\"))\n",
    "    response = client.responses.create(\n",
    "                  model=\"gpt-4.1\", # or the latest version of GPT, o4-mini, gpt-4o, o3, gpt-4.1\n",
    "                  temperature=0,\n",
    "                  input=f\"You are an expert in bioventure investing. Answer the following question: {prompt}\"\n",
    "                )\n",
    "    return response.output_text\n",
    "\n",
    "\n",
    "def answer_online_search(prompt,search_model=\"o4-mini\"):\n",
    "    \n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key = get_key(\"openai-api-key\",\"us-west-2\"))\n",
    "    response = client.responses.create(\n",
    "                  model= search_model,    #o4-mini, o3\n",
    "                  tools=[{\"type\": \"web_search_preview\",\n",
    "                          \"search_context_size\": \"high\",}],\n",
    "                  input=f\"{prompt}\"                    \n",
    "                )\n",
    "    return response.output_text\n",
    "\n",
    "\n",
    "\n",
    "def origene_mcp(prompt, search_model=\"o4-mini\"):\n",
    "    \n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key = get_key(\"openai-api-key\",\"us-west-2\"))\n",
    "    response = client.responses.create(\n",
    "                model=search_model,\n",
    "                tools=[\n",
    "                    {\"type\": \"mcp\",\n",
    "                     \"server_label\": \"origene\",\n",
    "                     \"server_url\": \"https://origene-uuid1752754854.app-space.dplink.cc/chembl_mcp/mcp/?token=172f53102e0a46acb20f306eceaaf6c4\",\n",
    "                     \"require_approval\": \"never\",\n",
    "                    },],\n",
    "                input= f\"{prompt}\"\n",
    "                )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###take too long to run\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(api_key = get_key(\"openai-api-key\",\"us-west-2\"))\n",
    "# response = client.responses.create(\n",
    "#             model=\"o4-mini\",\n",
    "#             tools=[\n",
    "#                 {\"type\": \"mcp\",\n",
    "#                  \"server_label\": \"disease-pocket-molecule-mcp\",\n",
    "#                  \"server_url\": \"https://disease-pocket-molecule-mcp-uuid1751524197.app-space.dplink.cc/sse?token=4218554daa854930947d4986b1fb35e9\",\n",
    "#                  \"require_approval\": \"never\",\n",
    "#                 },],\n",
    "#             input= \"find all targets associated with obesity\"\n",
    "#             )\n",
    "# print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f88ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(answer_online_search(\"Comprehensively list all the biotech companies that are competitors to PPInnova (Peak Perform Innova).\",\"o4-mini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75df770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(answer_online_search(\"Comprehensively list all the biotech companies with active programs targeting ALK7 for indication Obesity, T2D.\",\"o4-mini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa1008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(answer_online_search(\"tell me about Sidera Bio\",\"o3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fd4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(answer_online_search(\"For company Trevi Therapeutics, search google finance to provide the following\\\n",
    "#                                     information for the recent past 3, 6, 12 months: The highest and lowest stock prices,\\\n",
    "#                                     along with the corresponding dates. The largest single-day stock price change (either gain\\\n",
    "#                                     or loss) during that period, including the amount and the date it occurred.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c340181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_search_ensemble(question, bm25_retriever, k_bm, db_jd, k_jd, search_model=\"gpt-4.1\", priority_order=['online_search', 'jarvis_docs']):\n",
    "        \n",
    "    # Retrieve documents from docs    \n",
    "    bm25_retriever.k = k_bm\n",
    "    vector_retriever = db_jd.as_retriever(search_kwargs={\"k\": k_jd})\n",
    "    \n",
    "    ensemble = EnsembleRetriever(retrievers=[bm25_retriever, vector_retriever],\n",
    "                                 weights=[0.5, 0.5])\n",
    "\n",
    "    jarvis_docs_docs = ensemble.get_relevant_documents(question)\n",
    "    \n",
    "    # Get online_search response if required\n",
    "    online_search_response = answer_online_search(question, search_model) if 'online_search' in priority_order else \"\"\n",
    "    \n",
    "    # Create source-to-context mapping\n",
    "    source_contexts = {\n",
    "        'jarvis_docs': [d.page_content for d in jarvis_docs_docs],\n",
    "        'online_search': [online_search_response] if online_search_response else []\n",
    "    }    \n",
    "    \n",
    "#     combined_contexts = []\n",
    "#     for source in priority_order:\n",
    "#         if source in source_contexts:\n",
    "#             combined_contexts += (source_contexts[source])\n",
    "    \n",
    "    # Build the knowledge base from each source\n",
    "    knowledge_base = {\n",
    "        'jarvis_docs': \"\\n\\n\".join(d.page_content for d in jarvis_docs_docs) if 'jarvis_docs' in priority_order else \"\",\n",
    "        'online_search': online_search_response if 'online_search' in priority_order else \"\"\n",
    "    }\n",
    "    \n",
    "    # Build prioritized context using the given priority order.\n",
    "    priority_context = []\n",
    "    for idx, source in enumerate(priority_order, 1):\n",
    "        heading = {\n",
    "            'jarvis_docs': f\"{idx}. JARVIS Docs\",\n",
    "            'online_search': f\"{idx}. External Search\"\n",
    "        }[source]\n",
    "        \n",
    "        content = knowledge_base[source] or f\"No {source} data available\"\n",
    "        priority_context.append(f\"{heading}:\\n{content}\")\n",
    "    \n",
    "    # Generate source counts for jarvis_tables and jarvis_docs\n",
    "#     source_counts = {\n",
    "#         'jarvis_tables': Counter(os.path.basename(doc.metadata['source']) for doc in jarvis_tables_docs) if knowledge_base['jarvis_tables'] else Counter(),\n",
    "#         'jarvis_docs': Counter(os.path.basename(doc.metadata['source']) for doc in jarvis_docs_docs) if knowledge_base['jarvis_docs'] else Counter(),\n",
    "#         'external_sources': \"online_search:1\" if knowledge_base['online_search'] else \"online_search:0\"\n",
    "#     }\n",
    "    \n",
    "#     overview_images = list({\n",
    "#         m['overview_image'] for m in (doc.metadata for doc in jarvis_docs_docs) if 'overview_image' in m\n",
    "#     })\n",
    "    \n",
    "    # Precompute the joined priority context to avoid issues with backslashes in f-string expressions.\n",
    "    joined_priority_context = \"\\n\\n\".join(priority_context)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "**Analysis Directive**: Answer using this priority sequence: {', '.join(priority_order).upper()}\n",
    "\n",
    "**Knowledge Base**:\n",
    "{joined_priority_context}\n",
    "\n",
    "**Conflict Resolution Rules**:\n",
    "- Follow {priority_order[0].upper()} for numerical disputes\n",
    "- Resolve conceptual conflicts using {priority_order[0].upper()}\n",
    "- Use most recent context when dates conflict\n",
    "\n",
    "**Question**: {question}\n",
    "\n",
    "**Response Requirements**:\n",
    "Do not fabricate any information that is not in the given content.\n",
    "Answer in formal written English, be objectively and factually, avoid subjective adjectives or exaggerations.\\\n",
    "Please provide a response with a concise introductory phrase,\n",
    "but avoid meaningless fillers like 'ok', 'sure' or 'certainly'. Focus on delivering a direct and informative answer.\n",
    "Please bold the most important facts or conclusions in your answer to help readers quickly identify key information,\\\n",
    "especially when the response is long.\n",
    "Do not include reference filenames in the answer.\n",
    "\"\"\"\n",
    "    \n",
    "    return answer_gpt(prompt), online_search_response    #combined_contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96cc630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question1=f\"\"\"Which financing round (e.g. seed, series A, series B, etc) of company {COMPANY_NAME} is currently in.\"\"\"\n",
    "# result, source_counts, overview_images = answer_with_image_old(question1, db, 50)\n",
    "# print(result, f\"\\n\\n{source_counts}\", f\"\\n\\nnum of images: {len(overview_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###test\n",
    "def answer_perplexity_search_test(prompt):\n",
    "    \n",
    "    perplexity_api_key = get_key(\"perplexity-api-key\", \"us-west-2\")\n",
    "\n",
    "    # Build the payload for the Perplexity ai API.\n",
    "    payload = {\n",
    "        \"model\": \"sonar-reasoning-pro\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You have extensive expertise in biotech investments.\\\n",
    "            At the end of your answer, make sure to include all the online sources' full URLs you used for your think process.\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"answer the following question:{prompt}\"}\n",
    "        ],\n",
    "        \"max_tokens\": 8000,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"search_domain_filter\": None,\n",
    "        \"return_images\": False,\n",
    "        \"return_related_questions\": False,\n",
    "        \"stream\": False,\n",
    "        \"response_format\": None\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {perplexity_api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Call the Perplexity ai API.\n",
    "    response = requests.post(\"https://api.perplexity.ai/chat/completions\", json=payload, headers=headers)\n",
    "    response.raise_for_status()  # Ensure that an HTTP error raises an exception.\n",
    "    \n",
    "    result_json = response.json()\n",
    "    \n",
    "    # Extract the answer from the API response.\n",
    "    full_response = result_json['choices'][0]['message']['content']\n",
    "    \n",
    "#     # Split response into thinking process and final answer\n",
    "#     if \"**Final Answer**\" in full_response:\n",
    "#         answer = full_response.split(\"**Final Answer**\")[-1].strip()\n",
    "#     else:  # Fallback if formatting changes\n",
    "#         answer = full_response.split(\"\\n\\n\")[-1].strip()\n",
    "        \n",
    "    return full_response    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_helper(company_name):\n",
    "    \n",
    "    question = f\"\"\"\n",
    "    Extract structured facts about the drug pipelines of company {COMPANY_NAME}.\n",
    "    Return ONLY a JSON object with company-level information and its key assets.\n",
    "    Include only assets with a known asset name.\n",
    "    If no assets are found, return an empty assets list.\n",
    "\n",
    "    JSON structure:\n",
    "    {{\n",
    "      \"company name\": \"{COMPANY_NAME}\",\n",
    "      \"has platform\": true | false | null,\n",
    "      \"platform name\": \"<name, else null>\",\n",
    "      \"platform is core asset\": true | false | null,\n",
    "      \"assets\": [\n",
    "        {{\n",
    "          \"asset name\": \"<name, else null>\",\n",
    "          \"modality\": \"<name, else null>\",\n",
    "          \"targets\": [\"...\"],\n",
    "          \"targeted therapeutic areas\": [\"...\"],  \n",
    "          \"targeted indications\": [\"...\"],\n",
    "          \"current development stage\": \"<name, else null>\", \n",
    "          \"brief trial result\": \"<brief description, else null>\",\n",
    "          \"companies with competing asset\":[\"...\"],\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    result, online_search_response = answer_with_search_ensemble(question, bm25_retriever, 100, db_jd, 100, search_model=\"o4-mini\", priority_order=[\"jarvis_docs\"])\n",
    "    \n",
    "    return result\n",
    "\n",
    "    \n",
    "\n",
    "def prompt_format(json_string):\n",
    "    \n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=get_key(\"openai-api-key\", \"us-west-2\"))\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",  # Use the latest GPT-4 model you have access to\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\"You are an expert in json structure.\")\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"I want you to review the json string and make sure it's properly formatted.\\\n",
    "                Return the correct formatted json string of {json_string} as the output.\\\n",
    "                Please only return the json string, do not add any introductory phrase.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response_string=response.choices[0].message.content\n",
    "    json_match = re.search(r'{.*}', response_string, re.DOTALL)\n",
    "    if json_match:\n",
    "        json_content = json_match.group()\n",
    "        # Parse the JSON content to ensure it is valid\n",
    "        try:\n",
    "            parsed_json = json.loads(json_content)\n",
    "            return parsed_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"No JSON object found in the input string.\")\n",
    "        return None    \n",
    "\n",
    "\n",
    "def company_extractor(COMPANY_NAME):\n",
    "    \n",
    "    info = company_helper(COMPANY_NAME)\n",
    "    format_info = prompt_format(info)\n",
    "    \n",
    "    return format_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57226b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COMPANY_NAME = \"PPInnova (Peak Perform Innova)\"\n",
    "company_info = company_extractor(COMPANY_NAME)\n",
    "company_info    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a0b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### human review to update some info\n",
    "company_info[\"platform is core asset\"] = True\n",
    "substrings = ['STAT6', 'RBM39']\n",
    "company_info['assets'] = [asset for key in substrings for asset in company_info['assets'] if key in asset['asset name']]\n",
    "for asset in company_info[\"assets\"]:\n",
    "#     if \"EHT102\" in asset[\"asset name\"]:\n",
    "#         to_remove = [\"RRGENE\", \"Fudan University\"]\n",
    "#         to_add = [\"HuidaGene Therapeutics\",]\n",
    "#         asset[\"companies with competing asset\"] = [s for s in asset[\"companies with competing asset\"] if not any(sub in s for sub in to_remove)]\n",
    "    \n",
    "    asset['competitor_valuation'] = []   \n",
    "    for company in asset['companies with competing asset']:\n",
    "        print(f\"Getting valuation for {company}...\")        \n",
    "        query = f\"\"\"If {company} is a private company, provide its latest post-money valuation.\n",
    "                    If {company} was acquired, provide the acquisition deal size.\n",
    "                    If {company} is public, fetch its latest market cap from Google Finance.\"\"\"\n",
    "        result = answer_online_search(query, \"o4-mini\")\n",
    "        asset['competitor_valuation'].append(result)\n",
    "        time.sleep(1)\n",
    "        \n",
    "# for asset in company_info[\"assets\"]:\n",
    "#     if \"EHT102\" in asset[\"asset name\"]:\n",
    "#         asset[\"targeted indications\"] = [\"Obesity\",\"T2D\"]\n",
    "#     if \"FGF21\" in asset[\"asset name\"]:\n",
    "#         asset[\"targeted indications\"] = ['Chronic Kidney Disease (CKD)', 'Diabetic Kidney Disease (DKD)', 'Metabolic dysfunction-associated steatohepatitis (MASH)']\n",
    "        \n",
    "company_info        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917109f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ### human review to update some info\n",
    "# company_info[\"platform is core asset\"] = False\n",
    "# company_info['assets'] = [asset for asset in company_info['assets'] if asset['asset name'] in ['EHT102','EHT201']]\n",
    "\n",
    "# for asset in company_info[\"assets\"]:\n",
    "#     if \"EHT102\" in asset[\"asset name\"]:\n",
    "#         to_remove = [\"RRGENE\", \"Fudan University\"]\n",
    "#         to_add = [\"Emaygene\"]\n",
    "#         asset[\"companies with competing asset\"] = [s for s in asset[\"companies with competing asset\"] if not any(sub in s for sub in to_remove)]\n",
    "#         asset[\"companies with competing asset\"].extend(to_add)\n",
    "    \n",
    "#     if \"EHT201\" in asset[\"asset name\"]:\n",
    "#         to_add = [\"Decibel Therapeutics\",\n",
    "#                   \"Otonomy & AGTC (OTO-825)\",\n",
    "#                   \"Harvard Medical School - David Corey\",\n",
    "#                   \"Southeast University (Chai Renjie) Program\",\n",
    "#                   \"Juntendo University - Kazusaku Kamiya\"\n",
    "#                  ]\n",
    "#         asset[\"companies with competing asset\"].extend(to_add)\n",
    "    \n",
    "#     # Get competitor valuations for all assets\n",
    "#     asset['competitor_valuation'] = []\n",
    "#     for company in asset['companies with competing asset']:\n",
    "#         print(f\"Getting valuation for {company}...\")\n",
    "#         query = f\"\"\"If {company} is a private company, provide its latest post-money valuation.\n",
    "#                     If {company} was acquired, provide the acquisition deal size.\n",
    "#                     If {company} is public, fetch its latest market cap from Google Finance.\"\"\"\n",
    "#         result = answer_online_search(query, \"o4-mini\")\n",
    "#         asset['competitor_valuation'].append(result)\n",
    "#         time.sleep(1)\n",
    "\n",
    "# company_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdfacf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COMPANY_NAME = \"Sidera Bio\"\n",
    "\n",
    "question1=f\"\"\"\n",
    "Outline the deal terms associated with company {COMPANY_NAME}'s current financing round.\n",
    "\"\"\"\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 25, db_jd, 25, search_model=\"o4-mini\", priority_order=[\"jarvis_docs\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd1a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22f9e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COMPANY_NAME = \"Euhearing Therapeutics\"\n",
    "\n",
    "question1=f\"\"\"\n",
    "For company Euhearing Therapeutics's asset EHT102's targeted indication OTOF-related deafness, DFNB9 congenital hearing loss,\n",
    "estimate the diagnosed and\n",
    "total patient populations in the USA, Europe, and globally. \n",
    "Based on incidence and prevalence rates,\n",
    "note whether patient numbers are growing or declining, and define the therapy-eligible population\n",
    "considering line of therapy, disease stage, or biomarker subgroups. Estimate the global total\n",
    "addressable market (in U.S. dollars). \n",
    "Propose an annual price relative to the standard of care,                    \n",
    "estimate peak sales at a reasonable market-share penetration.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o4-mini\", priority_order=[\"jarvis_docs\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031a242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COMPANY_NAME = \"Euhearing Therapeutics\"\n",
    "\n",
    "question1=f\"\"\"\n",
    "Describe the clinical trial process and result of asset EHT101 in company Euhearing Therapeutics.\n",
    "\"\"\"\n",
    "\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o3\", priority_order=[\"jarvis_docs\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253af7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question1=f\"\"\"\n",
    "For company Euhearing Therapeutics's asset EHT102's targeted indication OTOF-related deafness, DFNB9 congenital hearing loss,\n",
    "estimate the diagnosed and prevalent patient populations in China, and the population asset EHT102 can target.\n",
    "Show your estimation process step by step.\n",
    "\"\"\"\n",
    "\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o3\", priority_order=[\"online_search\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634fff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question1=f\"\"\"\n",
    "For asset EHT102's targeted indication OTOF-related deafness, DFNB9 congenital hearing loss,\n",
    "estimate the diagnosed and prevalent patient populations in China, and the population asset EHT102 can target.\n",
    "Show your estimation process step by step.\n",
    "\"\"\"\n",
    "\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o4-mini\", priority_order=[\"online_search\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbddd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c72d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COMPANY_NAME = \"Euhearing\"\n",
    "\n",
    "question1=f\"\"\"\n",
    "For asset EHT102's targeted indication OTOF-related deafness, DFNB9, estimate the diagnosed and\n",
    "prevalent patient populations in China, and the population asset EHT102 can target in China.\n",
    "Validate your data assumption with latest reports or literatures.\n",
    "Show your estimation process step by step and list the reference links you used.\"\"\"\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o4-mini\", priority_order=[\"online_search\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b795af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "company_name = \"Euhearing Therapeutics\"\n",
    "\n",
    "question1=f\"\"\"\n",
    "For asset EHT102, please provide a well‑organized response of its\n",
    "Competitive Context: comprehensively list all biotech companies with active programs targeting OTOF\n",
    "for indication OTOF-related deafness, DFNB9, such as competitors Decibel Therapeutics (DB-OTO),\n",
    "Akouos (AK-OTOF), Sensorion/Pasteur Institute (SENS-501/OTOF-GT), Otovia Therapeutics (OTOV101N+OTOV101C),\n",
    "HuidaGene Therapeutics (AAV-gOTOF-emxABE), EmayGene (EA0010), Katholieke Universiteit Leuven (WO2025003513A1).\n",
    "For each competitor, include: program, modality, clinical phase/status, key distinguishing features,\n",
    "and financial information according to the following rules:        \n",
    "- If the competitor is a private company, provide its latest post-money valuation.\n",
    "- If the competitor was acquired, provide the acquisition deal size.\n",
    "- If the competitor is public, fetch its **current** market cap using Google Finance and include the Google Finance URL. \n",
    "Do not use any other data sources for market cap.\n",
    "Present the information in a structured table, followed by a concise descriptive summary.\"\"\"\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o4-mini\", priority_order=[\"jarvis_docs\",\"online_search\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd92979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(online_search_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ced21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COMPANY_NAME = \"Euhearing Therapeutics\"\n",
    "\n",
    "question1=f\"\"\"\n",
    "Asset EHT102 is targeting OTOF-related deafness via Gene therapy (dual-AAV, protein-level recombination via intein).\n",
    "For asset EHT102's targeted indication OTOF-related deafness, estimate the diagnosed and\n",
    "prevalent patient populations in China, and the population asset EHT102 can target in China.\\\n",
    "Validate your data assumption with latest reports or literatures. \n",
    "Show your estimation process step by step and list the reference links you used.\n",
    "\"\"\"\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o4-mini\", priority_order=[\"online_search\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea97613",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY_NAME = \"Euhearing Therapeutics\"\n",
    "\n",
    "question1=f\"\"\"\n",
    "Asset EHT102 is targeting OTOF-related deafness via Gene therapy (dual-AAV, protein-level recombination via intein).\n",
    "Consider the price of current SoC for OTOF-related deafness and price of gene therapy for other rare diseases in China,\\\n",
    "come up an reasonable price for EHT102 in China.\\\n",
    "Validate your data assumption with latest reports or literatures. \n",
    "Show your estimation process step by step and list the reference links you used.\n",
    "\"\"\"\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o4-mini\", priority_order=[\"online_search\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9f02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "company_name = \"Euhearing Therapeutics\"\n",
    "\n",
    "question1=f\"\"\"\n",
    "Briefly state how we (Pivotal BioVenture Partners) learn about the company {company_name}.\\\n",
    "                            Then describe the previous financing history of company {company_name} prior to\\\n",
    "                            the current round. What rounds of funding has the company previously completed (size,\\\n",
    "                            investors etc.), and what were the key milestones achieved with each round? For company\\\n",
    "                            {company_name}'s most recent prior financing round, how much was raised and what were\\\n",
    "                            the pre-money and post-money valuation of the round?\\\n",
    "                            Please provide a single, cohesive paragraph to address all the questions.\n",
    "\"\"\"\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o4-mini\", priority_order=[\"jarvis_docs\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43051c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(online_search_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=db_jd.similarity_search_with_relevance_scores(question1, 50)   #similarity_search, similarity_search_with_score, similarity_search_with_relevance_scores\n",
    "for chunk, score in documents:\n",
    "    print(chunk.metadata['source'])\n",
    "    print(score)\n",
    "    print(chunk.page_content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0afd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever.k = 50\n",
    "vector_retriever = db_jd.as_retriever(search_kwargs={\"k\": 50})\n",
    "\n",
    "ensemble = EnsembleRetriever(retrievers=[bm25_retriever, vector_retriever],\n",
    "                             weights=[0.5, 0.5])\n",
    "\n",
    "jarvis_docs_docs = ensemble.get_relevant_documents(question1)\n",
    "[d.page_content for d in jarvis_docs_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4117d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY_NAME = \"Euhearing Therapeutics\"\n",
    "\n",
    "question1=f\"\"\"\n",
    "The asset EHT102 in company Euhearing Therapeutics's pipeline is in development stage Phase 1/2 (IND filed, first injection Dec 2024).                            If the asset EHT102 is in clinical stage, depending on the trial phase, provide the following:                            If the asset EHT102 is in Phase 1, describe the study                            design (including randomization, blinding, and control arms if used), participant type and number                            (healthy volunteers or patients), primary endpoints, and summarize quantitative results                            for safety, dose-limiting toxicities, and tolerability; additionally, provide any                            exploratory changes of biomarker data or preliminary signals of efficacy with concrete numberic results.                             If the asset EHT102 is in Phase 2, detail the study design (e.g., dose-finding, proof-of-concept), patient                            population and inclusion/exclusion criteria, primary and secondary endpoints (often initial                            efficacy and extended safety), and present efficacy and safety results using concrete quantitative                            metrics (response rates, changes in relevant biomarkers, mean differences, etc.), p-values, and                            interpret whether the results support advancement to pivotal trials.                            If the asset EHT102 is in Phase 3, provide a comprehensive summary of the pivotal study design (randomization, control arms,                            multicenter participation), number of patients, detailed definitions of all primary and secondary                            endpoints, and full clinical results, including efficacy, safety, effect sizes, risk reductions,                            confidence intervals, and p-values, clearly assessing if the trial met its primary objectives and                            is likely to support regulatory approval or label expansion.                            For the trial, specify if the outcome was positive, negative, or inconclusive based on primary endpoints,                            and interpret the significance of the findings in light of current clinical standards                            and patient population needs. Note any missing data or information gaps.                            If the asset EHT102 is not in clinical stage, simply state that it's not in clinical stage.\"\"\"\n",
    "result, online_search_response = answer_with_search_ensemble(question1, bm25_retriever, 50, db_jd, 50, search_model=\"o4-mini\", priority_order=[\"jarvis_docs\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d453dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc620b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=db_jt.similarity_search_with_relevance_scores(question1, 100)   #similarity_search, similarity_search_with_score, similarity_search_with_relevance_scores\n",
    "for chunk, score in documents:\n",
    "    print(chunk.metadata['source'])\n",
    "    print(score)\n",
    "    print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c4776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9f954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
